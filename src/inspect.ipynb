{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import uniformDataset, contextUniformDataset\n",
    "from model import MLP\n",
    "from train import train_model, evaluate_model\n",
    "from test import test_model\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 4 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: real train/dev/test dataset\n",
    "# TODO: training curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"torch version: %s\" % torch.__version__)\n",
    "print(\"np version: %s\" % np.__version__)\n",
    "print(\"__debug__: %s\" % __debug__)\n",
    "print(\"cuda: %s\" % cuda)\n",
    "print(\"num_workers: %s\" % num_workers)\n",
    "print(\"device: %s\" % device)\n",
    "print(\"verbose: %s\" % verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "path_trainx = \"%s/train.npy\" % data_path\n",
    "path_trainy = \"%s/train_labels.npy\" % data_path\n",
    "path_evalx = \"%s/dev.npy\" % data_path\n",
    "path_evaly = \"%s/dev_labels.npy\" % data_path\n",
    "path_testx = \"%s/test.npy\" % data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalx = np.load(path_evalx, allow_pickle=True)\n",
    "evaly = np.load(path_evaly, allow_pickle=True)\n",
    "\n",
    "# trainx = np.load(path_trainx, allow_pickle=True) # Note: for real training\n",
    "# trainy = np.load(path_trainy, allow_pickle=True) # Note: for real training\n",
    "trainx = evalx # Note: for development\n",
    "trainy = evaly # Note: for development\n",
    "\n",
    "testx = np.load(path_testx, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "orig_x_dim, orig_y_dim = evalx[0].shape[1], 138\n",
    "context_size = 5\n",
    "input_size, output_size = orig_x_dim * (2*context_size+1), orig_y_dim\n",
    "size_list = [input_size, 256, output_size] # TODO: change this\n",
    "activation = nn.ReLU # use only one type of activation\n",
    "lr = 1e-3 # default lr is 1e-3\n",
    "epochs = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loader\n",
    "print(\"loading data...\")\n",
    "\n",
    "train_dataset = contextUniformDataset(trainx, trainy, context_size=context_size)\n",
    "# eval_dataset = contextUniformDataset(evalx, evaly, context_size=context_size) # for real training\n",
    "eval_dataset = train_dataset # for development\n",
    "test_dataset = contextUniformDataset(testx, is_test=True, context_size=context_size)\n",
    "\n",
    "# TODO: average #frames in one utterance in train dataset\n",
    "batch_size = len(train_dataset) // train_dataset.utter_num\n",
    "\n",
    "if verbose:\n",
    "    print(\"train size: X:({}, {}) Y:({}, 1)\".format(len(train_dataset), len(train_dataset[0][0]), len(train_dataset)))\n",
    "    print(\"eval size: X:({}, {}) Y:({}, 1)\".format(len(eval_dataset), len(eval_dataset[0][0]), len(eval_dataset)))\n",
    "    print(\"test size: X:({}, {})\".format(len(test_dataset), len(test_dataset[0])))\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, # The dataset\n",
    "    batch_size=batch_size,      # Batch size\n",
    "    shuffle=True,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   # Copy data to CUDA pinned memory\n",
    "    num_workers=num_workers      # Number of worker processes for loading data.\n",
    "                       )\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "print(\"building model...\")\n",
    "\n",
    "model = MLP(size_list, activation)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "print(\"training...\")\n",
    "train_losses, eval_losses, eval_accs = \\\n",
    "    train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"predicting...\")\n",
    "predicts = test_model(model, test_loader, device, save=True)\n",
    "print(\"finished\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
