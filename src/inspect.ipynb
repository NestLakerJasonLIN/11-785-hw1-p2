{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import uniformDataset\n",
    "from model import MLP\n",
    "from train import train_model, evaluate_model\n",
    "from test import test_model\n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 8 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: real train/dev/test dataset\n",
    "# TODO: training curves\n",
    "# TODO: concatenate context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 1.3.1\n",
      "np version: 1.17.4\n",
      "__debug__: True\n",
      "cuda: False\n",
      "num_workers: 0\n",
      "device: cpu\n",
      "verbose: True\n"
     ]
    }
   ],
   "source": [
    "print(\"torch version: %s\" % torch.__version__)\n",
    "print(\"np version: %s\" % np.__version__)\n",
    "print(\"__debug__: %s\" % __debug__)\n",
    "print(\"cuda: %s\" % cuda)\n",
    "print(\"num_workers: %s\" % num_workers)\n",
    "print(\"device: %s\" % device)\n",
    "print(\"verbose: %s\" % verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_trainx = \"../data/train.npy\"\n",
    "path_trainy = \"../data/train_labels.npy\"\n",
    "path_evalx = \"../data/dev.npy\"\n",
    "path_evaly = \"../data/dev_labels.npy\"\n",
    "path_testx = \"../data/test.npy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "evalx = np.load(path_evalx, allow_pickle=True)\n",
    "evaly = np.load(path_evaly, allow_pickle=True)\n",
    "\n",
    "testx = np.load(path_testx, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "train size: X:(675836, 40) Y:(675836, 1)\n",
      "eval size: X:(675836, 40) Y:(675836, 1)\n",
      "test size: X:(223592, 40)\n"
     ]
    }
   ],
   "source": [
    "# data loader\n",
    "print(\"loading data...\")\n",
    "\n",
    "train_dataset = uniformDataset(evalx, evaly) # TODO: change this to real train dataset\n",
    "eval_dataset = uniformDataset(evalx, evaly) # TODO: change this to real train dataset\n",
    "test_dataset = uniformDataset(testx, is_test=True)\n",
    "\n",
    "if verbose:\n",
    "    print(\"train size: X:({}, {}) Y:({}, 1)\".format(len(train_dataset), len(train_dataset[0][0]), len(train_dataset)))\n",
    "    print(\"eval size: X:({}, {}) Y:({}, 1)\".format(len(eval_dataset), len(eval_dataset[0][0]), len(eval_dataset)))\n",
    "    print(\"test size: X:({}, {})\".format(len(test_dataset), len(test_dataset[0])))\n",
    "\n",
    "batch_size = len(train_dataset) // train_dataset.utter_num # average #frames in one utterance in train dataset\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, # The dataset\n",
    "    batch_size=batch_size,      # Batch size\n",
    "    shuffle=True,      # Shuffles the dataset at every epoch\n",
    "    pin_memory=True,   # Copy data to CUDA pinned memory\n",
    "    num_workers=num_workers      # Number of worker processes for loading data.\n",
    "                       )\n",
    "\n",
    "eval_loader = DataLoader(\n",
    "    eval_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building model...\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "print(\"building model...\")\n",
    "\n",
    "size_list = [40, 256, 138] # TODO: change this\n",
    "model = MLP(size_list, nn.ReLU)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Training Loss:  5.30270888391784 Time:  12.655793905258179 s\n",
      "evaluate Loss:  3.6799234445261804\n",
      "evaluate Accuracy:  14.984848395172792 %\n",
      "====================\n",
      "Training Loss:  3.4598245200625772 Time:  10.821533918380737 s\n",
      "evaluate Loss:  3.346704479134375\n",
      "evaluate Accuracy:  19.899502246107044 %\n",
      "====================\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "print(\"training...\")\n",
    "epochs = 2\n",
    "train_losses, eval_losses, eval_accs = \\\n",
    "    train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting...\n"
     ]
    }
   ],
   "source": [
    "print(\"predicting...\")\n",
    "predicts = test_model(model, test_loader, device, save=True)\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
