{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "inspect.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz__rZDxiyX0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDkwjboCi4Ig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ! cp drive/My\\ Drive/11785/hw1_p2/*.py .\n",
        "# ! pip install tqdm==4.42.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVulVOP3ir1R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from dataset import uniformDataset, contextUniformDataset\n",
        "from model import MLP\n",
        "from train import train_model, evaluate_model\n",
        "from test import test_model\n",
        "from utils import *\n",
        "import os\n",
        "\n",
        "cuda = torch.cuda.is_available()\n",
        "num_workers = 4 if cuda else 0 \n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
        "verbose = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sfMvmNyVir1V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"torch version: %s\" % torch.__version__)\n",
        "print(\"np version: %s\" % np.__version__)\n",
        "print(\"__debug__: %s\" % __debug__)\n",
        "print(\"cuda: %s\" % cuda)\n",
        "print(\"num_workers: %s\" % num_workers)\n",
        "print(\"device: %s\" % device)\n",
        "print(\"verbose: %s\" % verbose)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ70mjO_FBk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID = 9\n",
        "checkpoint_path = \"drive/My Drive/11785/hw1_p2\"\n",
        "checkpoint_filename = \"{}/checkpoint_{}.tar\".format(checkpoint_path, ID)\n",
        "print(\"NOTE: current ID is {}!\".format(ID))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg6-IDmTir1Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "load_model = True\n",
        "data_path = \"drive/My Drive/11785/hw1_p2\"\n",
        "\n",
        "path_trainx = \"%s/train.npy\" % data_path\n",
        "path_trainy = \"%s/train_labels.npy\" % data_path\n",
        "path_evalx = \"%s/dev.npy\" % data_path\n",
        "path_evaly = \"%s/dev_labels.npy\" % data_path\n",
        "path_testx = \"%s/test.npy\" % data_path\n",
        "\n",
        "pred_filename = \"{}/test_pred_{}.csv\".format(data_path, ID)\n",
        "\n",
        "checkpoint = {}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QvnXoG6ir1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evalx = np.load(path_evalx, allow_pickle=True)\n",
        "evaly = np.load(path_evaly, allow_pickle=True)\n",
        "\n",
        "trainx = np.load(path_trainx, allow_pickle=True) # Note: for real training\n",
        "trainy = np.load(path_trainy, allow_pickle=True) # Note: for real training\n",
        "# trainx = evalx # Note: for development\n",
        "# trainy = evaly # Note: for development\n",
        "\n",
        "testx = np.load(path_testx, allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iiGR4rrir1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# hyper parameters\n",
        "orig_x_dim, orig_y_dim = trainx[0].shape[1], 138\n",
        "context_size = 12\n",
        "input_size, output_size = orig_x_dim * (2*context_size+1), orig_y_dim\n",
        "size_list = [input_size, 2048, 1024, 1024, 1024, 1024, 1024, 1024, 1024, 512, 512, output_size]\n",
        "activation = \"relu\" # use only one type of activation\n",
        "lr = 1e-3 # default lr is 1e-3\n",
        "epochs = 20\n",
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_WSmItUir1i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# data loader\n",
        "print(\"loading data...\")\n",
        "\n",
        "train_dataset = contextUniformDataset(trainx, trainy, context_size=context_size)\n",
        "eval_dataset = contextUniformDataset(evalx, evaly, context_size=context_size) # for real training\n",
        "# eval_dataset = train_dataset # for development\n",
        "# test_dataset = contextUniformDataset(testx, is_test=True, context_size=context_size)\n",
        "\n",
        "if verbose:\n",
        "    print(\"train size: X:({}, {}) Y:({}, 1)\".format(len(train_dataset), len(train_dataset[0][0]), len(train_dataset)))\n",
        "    print(\"eval size: X:({}, {}) Y:({}, 1)\".format(len(eval_dataset), len(eval_dataset[0][0]), len(eval_dataset)))\n",
        "    # print(\"test size: X:({}, {})\".format(len(test_dataset), len(test_dataset[0])))\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset, # The dataset\n",
        "    batch_size=batch_size,      # Batch size\n",
        "    shuffle=True,      # Shuffles the dataset at every epoch\n",
        "    pin_memory=True,   # Copy data to CUDA pinned memory\n",
        "    num_workers=num_workers      # Number of worker processes for loading data.\n",
        "                       )\n",
        "\n",
        "eval_loader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    pin_memory=True,\n",
        "    num_workers=num_workers\n",
        ")\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=batch_size,\n",
        "#     shuffle=False,\n",
        "#     pin_memory=True,\n",
        "#     num_workers=num_workers\n",
        "# )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XsN9Ocpir1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model\n",
        "print(\"building model...\")\n",
        "model = MLP(size_list, activation, batch_norm=True)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.to(device).parameters(), lr=lr)\n",
        "\n",
        "# check if load checkpoint\n",
        "if not os.path.exists(checkpoint_path) or not os.path.exists(checkpoint_filename):\n",
        "    print(\"checkpoint folder: %s does not exist. Initialize new checkpoint\" % checkpoint_path)\n",
        "    init_checkpoint(checkpoint)\n",
        "\n",
        "elif load_model and os.path.exists(checkpoint_filename):\n",
        "    print(\"checkpoint file %s exist. Be careful about overwriting checkpoint! \"\n",
        "          \"Load checkpoint\" % checkpoint_filename)\n",
        "    checkpoint = load_checkpoint(checkpoint_filename, model, optimizer)\n",
        "\n",
        "print_model_statistics(checkpoint)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoh-Vffxir1o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training\n",
        "print(\"training...\")\n",
        "train_losses, eval_losses, eval_accs = \\\n",
        "    train_model(model, epochs, train_loader, eval_loader, criterion, optimizer, \n",
        "                device, checkpoint=checkpoint, checkpoint_filename=checkpoint_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNQgmc27ir1q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"predicting...\")\n",
        "predicts = test_model(model, test_loader, device, save=True, filename=pred_filename)\n",
        "print(\"finished\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}