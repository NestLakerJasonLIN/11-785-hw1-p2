{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from model import MLP\n",
    "from test import test_model\n",
    "from utils import *\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from dataset import simpleDataset, uniformDataset, contextUniformDataset\n",
    "import os \n",
    "\n",
    "cuda = torch.cuda.is_available()\n",
    "num_workers = 4 if cuda else 0 \n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "verbose = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP24(nn.Module):\n",
    "    def __init__(self, size_list, activation=\"relu\", batch_norm=True):\n",
    "        super(MLP24, self).__init__()\n",
    "        layers = []\n",
    "        self.size_list = size_list\n",
    "        if batch_norm:\n",
    "            layers.append(nn.BatchNorm1d(num_features=size_list[0]))\n",
    "        for i in range(len(size_list) - 2):\n",
    "            layers.append(nn.Linear(size_list[i],size_list[i+1]))\n",
    "            if batch_norm:\n",
    "                layers.append(nn.BatchNorm1d(num_features=size_list[i+1]))\n",
    "            if activation is \"relu\":\n",
    "                layers.append(nn.ReLU())\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "        layers.append(nn.Linear(size_list[-2], size_list[-1]))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 24\n",
    "# hyper parameters\n",
    "orig_x_dim, orig_y_dim = 40, 138\n",
    "context_size = 16\n",
    "input_size, output_size = orig_x_dim * (2*context_size+1), orig_y_dim\n",
    "size_list = [input_size, 1024, 512, 512, 256, output_size]\n",
    "activation = \"relu\" # use only one type of activation\n",
    "lr = 1e-3 # default lr is 1e-3\n",
    "epochs = 20\n",
    "batch_size = 512\n",
    "\n",
    "# model\n",
    "print(\"building model...\")\n",
    "model24 = MLP24(size_list, activation)\n",
    "criterion24 = nn.CrossEntropyLoss()\n",
    "optimizer24 = optim.Adam(model24.to(device).parameters(), lr=1e-3)\n",
    "\n",
    "# check if load checkpoint\n",
    "if os.path.exists(\"../checkpoint/checkpoint_24.tar\"):\n",
    "    print(\"checkpoint file ../checkpoint/checkpoint_24.tar exist.\")\n",
    "    checkpoint24 = load_checkpoint(\"../checkpoint/checkpoint_24.tar\", \n",
    "                                 model24, optimizer24)\n",
    "\n",
    "print_model_statistics(checkpoint24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model 27\n",
    "# hyper parameters\n",
    "orig_x_dim, orig_y_dim = 40, 138\n",
    "context_size = 16\n",
    "input_size, output_size = orig_x_dim * (2*context_size+1), orig_y_dim\n",
    "size_list = [input_size, 512, 512, 512, 256, output_size]\n",
    "activation = \"relu\" # use only one type of activation\n",
    "lr = 1e-3 # default lr is 1e-3\n",
    "epochs = 15\n",
    "batch_size = 512\n",
    "\n",
    "# model\n",
    "print(\"building model...\")\n",
    "model27 = MLP(size_list, activation)\n",
    "criterion27 = nn.CrossEntropyLoss()\n",
    "optimizer27 = optim.Adam(model27.to(device).parameters(), lr=1e-3)\n",
    "\n",
    "# check if load checkpoint\n",
    "if os.path.exists(\"../checkpoint/checkpoint_27.tar\"):\n",
    "    print(\"checkpoint file ../checkpoint/checkpoint_27.tar exist.\")\n",
    "    checkpoint27 = load_checkpoint(\"../checkpoint/checkpoint_27.tar\", \n",
    "                                 model27, optimizer27)\n",
    "\n",
    "print_model_statistics(checkpoint27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data\"\n",
    "path_testx = \"%s/test.npy\" % data_path\n",
    "testx = np.load(path_testx, allow_pickle=True)\n",
    "test_dataset = contextUniformDataset(testx, is_test=True, context_size=context_size)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    "    num_workers=num_workers\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicts = torch.LongTensor().to(device)\n",
    "    \n",
    "with torch.no_grad():\n",
    "    model24.eval()\n",
    "    model27.eval()\n",
    "\n",
    "    model24.to(device)\n",
    "    model27.to(device)\n",
    "\n",
    "    # no target in test dataset/data loader\n",
    "    for batch_idx, data in enumerate(test_loader):\n",
    "        data = data.to(device)\n",
    "\n",
    "        outputs24 = model24(data)\n",
    "        outputs27 = model27(data)\n",
    "\n",
    "        output = outputs24 + outputs27\n",
    "\n",
    "        _, predict = torch.max(output.data, 1)\n",
    "\n",
    "        predicts = torch.cat([predicts, predict])\n",
    "\n",
    "assert predicts.shape[0] == len(test_loader.dataset)\n",
    "\n",
    "result = np.concatenate([np.arange(len(predicts)).reshape(-1, 1),\n",
    "                         predicts.detach().cpu().clone().numpy().reshape(-1, 1)], axis=1)\n",
    "np.savetxt(\"../data/test_pred_2427.csv\", result, fmt=\"%i\", delimiter=\",\", header=\"id,label\", comments=\"\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
